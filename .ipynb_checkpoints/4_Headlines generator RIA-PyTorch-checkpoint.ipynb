{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"colab":{"name":"4_Headlines generator RIA-PyTorch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KG6HGVJuhjfZ","colab_type":"text"},"source":["### Download input data from drive.google.com"]},{"cell_type":"code","metadata":{"id":"5dkq7TtqhbA1","colab_type":"code","outputId":"880afb5b-bb00-4dd7-fdc0-ddeda9392ebb","executionInfo":{"status":"ok","timestamp":1590501700449,"user_tz":-300,"elapsed":54904,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","!ls /content/gdrive/'My Drive'/nlp-project/input"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","ria_1k_.json  ria_1k.json  ria_20.json\tria.json.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_nNSTQM7iT1L","colab_type":"code","outputId":"e101f23e-ac3d-4d48-b796-c5b28ed6a5e3","executionInfo":{"status":"ok","timestamp":1590501775365,"user_tz":-300,"elapsed":12302,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!cp -r /content/gdrive/'My Drive'/nlp-project/input ./input/\n","!cp -r /content/gdrive/'My Drive'/nlp-project/src ./src\n","!ls /content/input/\n","!ls /content/src/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["ria_1k_.json  ria_1k.json  ria_20.json\tria.json.gz\n","model.py  params.py  test.py  train.py\tutils.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lyQ7YoWqhRfa","colab_type":"text"},"source":["# Generation of headlines for news articles in Russian with a sequence to sequence network and attention¶\n","```\n","1 Data Preparation\n","2 Exploring dataset\n","3  Model Implementation\n","    3.1  Encoder\n","    3.2  Decoder with Attention\n","3  Training Seq2Seq\n","4  Evaluating Seq2Seq\n","5  Summary\n"," Reference\n","```"]},{"cell_type":"markdown","metadata":{"id":"M-ZR2nrlBu6f","colab_type":"text"},"source":["### Requirements"]},{"cell_type":"code","metadata":{"id":"001ATX4YBv1J","colab_type":"code","outputId":"78ccfaee-cfc5-4c22-fd25-997b2984d177","executionInfo":{"status":"ok","timestamp":1590501778560,"user_tz":-300,"elapsed":13780,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from __future__ import unicode_literals, print_function, division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","import re\n","import random\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'USE_CUDA={device}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["USE_CUDA=cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yunRUGI7NUHT","colab_type":"text"},"source":["## Loading Data - read data files"]},{"cell_type":"code","metadata":{"id":"gMteLb51NTsa","colab_type":"code","outputId":"6a0f9e80-1373-45f5-e363-549db3608acc","executionInfo":{"status":"ok","timestamp":1590501778563,"user_tz":-300,"elapsed":12582,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":264}},"source":["data_path = 'input/ria_1k.json'\n","glove_path = 'input/glove.6B.50d.txt'\n","data = pd.read_json(data_path, lines=True)\n","print(f'raw text = {data[\"text\"][1]}\\nraw title = [{data[\"title\"][1]}]')\n","data.head(3)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["raw text = <p><strong></strong></p>\n","<p><strong>москва, 2 дек&nbsp;&mdash; риа новости.</strong> цена на&nbsp;нефть марки brent, ранее в&nbsp;понедельник падавшая до&nbsp;пятилетних минимумов, поднялась выше психологической отметки в&nbsp;73 доллара за&nbsp;баррель, свидетельствуют данные торгов.</p>\n","<p><img src=\"/img/article_icon.gif\" border=\"0\" hspace=\"5\" width=\"20\" height=\"20\" tag=\"[-json: {'type':'article','article_id':'1036106874'}-]\" />по состоянию на&nbsp;12.10 мск стоимость фьючерсов на&nbsp;североморскую смесь brent растет на&nbsp;0,5%&nbsp;&mdash; до&nbsp;72,88 доллара за&nbsp;баррель и&nbsp;уже поднималась до&nbsp;73,03 доллара. стоимость январских фьючерсов на&nbsp;легкую нефть марки wti снижалась на&nbsp;0,1%&nbsp;&mdash; до&nbsp;68,95 доллара за&nbsp;баррель.</p>\n","<p>ранее в&nbsp;ходе торгов фьючерсы на&nbsp;brent и&nbsp;wti дешевели до&nbsp;67,53 и&nbsp;63,72 доллара за&nbsp;баррель соответственно&nbsp;&mdash; минимумов с&nbsp;октября и&nbsp;июля 2009 года.</p>\n","<p>в четверг на&nbsp;166-м заседании в&nbsp;вене страны-члены опек решили сохранить квоту на&nbsp;добычу нефти на&nbsp;уровне 30 миллионов баррелей в&nbsp;день до&nbsp;следующего заседания организации в&nbsp;июне 2015 года. на этом фоне цены на&nbsp;нефть обновили многолетние минимумы.</p>\n","raw title = [цена на нефть марки brent поднялась выше $73 за баррель]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;p&gt;&lt;strong&gt;автор мария балябина &lt;br /&gt;&lt;/strong...</td>\n","      <td>украинская люстрация: жертвоприношение во власти</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;strong&gt;москва, 2...</td>\n","      <td>цена на нефть марки brent поднялась выше $73 з...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;strong&gt;бангкок, ...</td>\n","      <td>число пострадавших в аварии в таиланде россиян...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text                                              title\n","0  <p><strong>автор мария балябина <br /></strong...   украинская люстрация: жертвоприношение во власти\n","1  <p><strong></strong></p>\\n<p><strong>москва, 2...  цена на нефть марки brent поднялась выше $73 з...\n","2  <p><strong></strong></p>\\n<p><strong>бангкок, ...  число пострадавших в аварии в таиланде россиян..."]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"-NR_cafmlRmV","colab_type":"text"},"source":["## 1 Data Preparation\n","split the sentences into words and convert it into One-Hot Vector.\n","Each word will be indexed in the Lang class to make a dictionary. The Lang Class will store every text and split it word by word with the addSentence. Then create a dictionary by indexing every unknown word.\n","\n","### Indexing words\n","class Lang has \n","- word → index: (word2index) dictionary\n","- index → word: (index2word) dictionary,\n","- word2count: count of each word to use to\n","\n","```\n","# This is formatted as code\n","```\n","\n"," later replace rare words."]},{"cell_type":"code","metadata":{"id":"omaEg8p2iOQw","colab_type":"code","colab":{}},"source":["SOS_token = 0\n","EOS_token = 1\n","\n","#initialize Lang Class\n","class Lang:\n","    def __init__(self):\n","        #initialize containers to hold the words and corresponding index\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2 # Count SOS and EOS\n","\n","    #split a sentence into words and add it to the container\n","    def addSentence(self, sentence):\n","       for word in sentence.split(' '):\n","           self.addWord(word)\n","\n","    #If the word is not in the container, the word will be added to it, \n","    #else, update the word counter\n","    def addWord(self, word):\n","       if word not in self.word2index:\n","           self.word2index[word] = self.n_words\n","           self.word2count[word] = 1\n","           self.index2word[self.n_words] = word\n","           self.n_words += 1\n","       else:\n","           self.word2count[word] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qS2fU44iBgpe","colab_type":"text"},"source":["The Lang Class help us make a dictionary. For each text and title, every sentence will be split into words and then added to the container. Each container will store the words in the appropriate index, count the word, and add the index of the word so we can use it to find the index of a word or finding a word from its index.\n","\n","We have dataFrame with source texts and target titles. For every sentence we will\n","- normalize it to lower case,\n","- remove all non-character\n","- split the sentences, so have each word in it."]},{"cell_type":"code","metadata":{"id":"-R5AFHYrVqAu","colab_type":"code","outputId":"6e5c8029-f785-4581-bd60-4d3882463435","executionInfo":{"status":"ok","timestamp":1590501955793,"user_tz":-300,"elapsed":910,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def clear_text(text):\n","    text = text.lower()\n","    text = re.sub(r'\\b\\d+\\b', ' ',text)\n","    text = re.sub(r'\\(.*\\)',' ',text)\n","    text = re.sub(r'[^а-яА-Я0-9. ]',' ',text)\n","    text = re.sub(r'(\\s+.\\s+)',' ',text)\n","    text = re.sub(r'\\.',' . ',text)\n","    text = re.sub(r'^(\\b\\w+\\b\\s{,2}){,5}\\.',' ',text)\n","    text = ' '.join(text.split())\n","    return text\n","\n","def normalize_sentence(df, lang):\n","    clean_text = []\n","    for text in df[lang]:\n","        clean_text.append(clear_text(text))\n","    return pd.Series(data=clean_text, name=lang)\n","\n","def read_sentence(df, lang1, lang2):\n","    sentence1 = normalize_sentence(df, lang1)\n","    sentence2 = normalize_sentence(df, lang2)\n","    return sentence1, sentence2\n","\n","def read_file(loc, lang1, lang2):\n","   df = pd.read_json(loc, lines=True)\n","   return df\n","\n","\n","df = read_file(loc='input/ria_1k.json', lang1='text', lang2='title')\n","sentence1, sentence2 = read_sentence(df, lang1='text', lang2='title')\n","text_max_lenght = max([len(text.split()) for text in sentence1])\n","print(f'the article with maximum letngth has {text_max_lenght} tokens')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["the article with maximum letngth has 20097 tokens\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hvX77QSZvUMS","colab_type":"code","outputId":"39b71556-82ed-4664-f589-e5be03dd99a0","executionInfo":{"status":"ok","timestamp":1590504108757,"user_tz":-300,"elapsed":916,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["MAX_LENGTH = text_max_lenght+1\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]\n","\n","\n","def process_data(lang1,lang2):\n","    data_path = 'input/ria_1k.json'\n","#    lang1, lang2 = ('text', 'title')\n","\n","    df = read_file(loc=data_path, lang1='text', lang2='title')\n","    print(f\"Read {len(df)} sentence pairs\")\n","\n","    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n","    pairs = list(zip(sentence1,sentence2))\n","    pairs = filterPairs(pairs)\n","    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n","    print(\"Counting words...\")\n","\n","    lang = Lang()\n","    # pairs = []\n","    for pair in pairs:\n","        lang.addSentence(pair[0]+' '+pair[1])\n","\n","    return lang, pairs\n","\n","lang, pairs = process_data(lang1='text' ,lang2='title')"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Read 1000 sentence pairs\n","Trimmed to 1000 sentence pairs\n","Counting words...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XvXHMj-JZOUp","colab_type":"text"},"source":["## 2 Exploring dataset"]},{"cell_type":"code","metadata":{"id":"25TcjTo1ZPu9","colab_type":"code","outputId":"6447cde4-f40e-4fd7-dc1c-3f5d278a4b21","executionInfo":{"status":"ok","timestamp":1590504133615,"user_tz":-300,"elapsed":1041,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":371}},"source":["import matplotlib.pyplot as plt\n","def get_wors_stat():\n","    # length distribution\n","    text_count = []\n","    summary_count = []\n","    for sent in text:\n","        text_count.append(len(sent.split()))\n","    for sent in title:\n","        summary_count.append(len(sent.split()))\n","\n","    graph_df= pd.DataFrame()\n","    graph_df['text']=text_count\n","    graph_df['title']=summary_count\n","\n","    graph_df.hist(bins = 12,figsize=(15,5))\n","    plt.show()\n","    return\n","\n","def get_text_share(text, label, threshold):\n","    cnt=0\n","    for i in text:\n","        if(len(i.split())<=threshold):\n","            cnt=cnt+1\n","    print(f'{cnt/len(text):.2%} of {label}s have < {threshold} words')\n","\n","\n","text, title = [], []\n","for pair in pairs:\n","    text.append(pair[0])\n","    title.append(pair[1])\n","get_wors_stat()\n","get_text_share(text,'text', 300)\n","get_text_share(title,'title', 12)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["87.80% of texts have < 300 words\n","100.00% of titles have < 12 words\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x360 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"AFKJxp907_Uf","colab_type":"text"},"source":["Because there are texts of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n","\n","To train the network quickly, we will cut out the largest texts, while preserving the bulk of the dataset."]},{"cell_type":"code","metadata":{"id":"g9bHRx7dvFQI","colab_type":"code","outputId":"04cabe75-7aaa-4776-a350-8331b7c4fdb5","executionInfo":{"status":"ok","timestamp":1590504157772,"user_tz":-300,"elapsed":1065,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["MAX_LENGTH = 300\n","# Now reinitialize the dictionary and recreate the container with texts and titles\n","lang, pairs = process_data(lang1='text' ,lang2='title')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Read 1000 sentence pairs\n","Trimmed to 877 sentence pairs\n","Counting words...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c_lQs2DhnoIM","colab_type":"text"},"source":["## 3  Model Implementation\n","Unlike sequence prediction with one RNN, the seq2seq model frees us from the length and order of the sequence, which is suitable for summarizing texts.\n","\n"]},{"cell_type":"code","metadata":{"id":"6YsQuDwDZPmV","colab_type":"code","outputId":"d6f77c86-bf63-4939-a3c0-1993bef69024","executionInfo":{"status":"ok","timestamp":1590504165696,"user_tz":-300,"elapsed":1076,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["lang, pairs = process_data(lang1='text' ,lang2='title')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Read 1000 sentence pairs\n","Trimmed to 877 sentence pairs\n","Counting words...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QAl3ojK-nrQO","colab_type":"text"},"source":["###    3.1  Encoder\n"]},{"cell_type":"code","metadata":{"id":"dJ14IZw8ZPVH","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXSeOHV0nxXk","colab_type":"text"},"source":["###    3.3  Decoder with Attention"]},{"cell_type":"code","metadata":{"id":"7X41UnaBn0nd","colab_type":"code","colab":{}},"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQnNYFmVn3o8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jTeKl09q07RY","colab_type":"text"},"source":["##    4 Training Seq2Seq\n","### Preparing Training Data\n","converting pairs into Tensor is very important because our network only reads tensors.\n","\n","at every end of the text there will be a token to tell the network that the input is finished. For every word in the text, it will get the index from the appropriate word in the dictionary and add a token at the end of the text.\n","\n"]},{"cell_type":"code","metadata":{"id":"AspXUo6ptK-z","colab_type":"code","outputId":"86316555-d47e-47fc-e21b-fde1425478d3","executionInfo":{"status":"ok","timestamp":1590504170700,"user_tz":-300,"elapsed":391,"user":{"displayName":"Vadim Vlasov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgebvpEAbUfFGl4lBLW0xFpLYqE-198l3ks-O7F=s64","userId":"15321128647240960966"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def indexesFromSentence(lang, sentence):\n","   return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","   indexes = indexesFromSentence(lang, sentence)\n","   indexes.append(EOS_token)\n","   return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensorsFromPair(pair, input_lang=lang, output_lang=lang):\n","   input_tensor = tensorFromSentence(input_lang, pair[0])\n","   target_tensor = tensorFromSentence(output_lang, pair[1])\n","   return (input_tensor, target_tensor)\n","\n","i=0\n","print(f'pait No {i} => input tenzor={tensorsFromPair(pairs[i])[0].shape}, output tenzor={tensorsFromPair(pairs[i])[1].shape}')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["pait No 0 => input tenzor=torch.Size([112, 1]), output tenzor=torch.Size([9, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hKE6CnL9z7ID","colab_type":"text"},"source":["### 4.1 Training the Model"]},{"cell_type":"code","metadata":{"id":"retUcy6-wpF0","colab_type":"code","colab":{}},"source":["teacher_forcing_ratio = 0.5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e73SdbhHwo-j","colab_type":"code","colab":{}},"source":["# This is a helper function to print time elapsed and estimated time remaining given the current time and progress %.\n","import time\n","import math\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UobyVeIwo0v","colab_type":"code","colab":{}},"source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ltqK72Mr1Em7","colab_type":"text"},"source":["### 4.2 Plotting results"]},{"cell_type":"code","metadata":{"id":"CnS2YnQIwotZ","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PJ-Hh0Hq1NEw","colab_type":"text"},"source":["### 4.3 Evaluation\n","Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder’s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder’s attention outputs for display later.\n","\n"]},{"cell_type":"code","metadata":{"id":"ndn6pU4I1DaA","colab_type":"code","colab":{}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HnKYHCb41p3g","colab_type":"text"},"source":["We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"]},{"cell_type":"code","metadata":{"id":"a0l_RF7E1pB0","colab_type":"code","colab":{}},"source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMLCJUzH1ujH","colab_type":"text"},"source":["### 4.4 Training and Evaluating"]},{"cell_type":"code","metadata":{"id":"a3KBirqD1DPP","colab_type":"code","colab":{}},"source":["hidden_size = 256\n","encoder1 = EncoderRNN(lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XRoyQUQ8anB","colab_type":"code","colab":{}},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtVCdsJt8aiX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9W-kiqm_qSEC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bOOiOreF1dyL","colab_type":"text"},"source":["## 5 ROUGE Score Evaluation\n","https://github.com/pcyin/PyRouge"]},{"cell_type":"code","metadata":{"id":"VIZ7uZ8zqR-9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xf0Ni6LzqR0D","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHkiQfNup15S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLpYc_88p1vj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bq1B74iKhRgP","colab_type":"text"},"source":[" ## TODO further work\n","- use PyRouge for ROUGE Score Evaluation\n","- use pretrained word embedings\n","- use with more layers\n","- Get dataset from https://ru.investing.com/news/economy"]},{"cell_type":"code","metadata":{"id":"xCyiowBThRgX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nA9BDdBmhRga","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LDPV2ArhhRgc","colab_type":"text"},"source":["# References:\n","\n","1. NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n","2. SEQ2SEQ WITH ATTENTION. https://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/seq2seq/2_torch_seq2seq_attention.ipynb\n","3. Auto-highlighter: extractive text summarization with sequence-to-sequence model. https://medium.com/@rimacyn_23654/auto-highlighter-extractive-text-summarization-with-sequence-to-sequence-model-cbbf333772bf"]}]}